{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrST1lWYkFndyH3VXWB53G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwisenlared/MasterThesis/blob/master/ImageGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozNrHqvp_dFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuiQx2avBBDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "db865072-f90d-4389-dcf3-3688ceba894a"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/weird images\" -d \"/content/drive/My Drive/images\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/My Drive/Colab Notebooks/weird images, /content/drive/My Drive/Colab Notebooks/weird images.zip or /content/drive/My Drive/Colab Notebooks/weird images.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMW4PsbMBaeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03af778b-a86d-4752-9154-6f7ff1b9e3c4"
      },
      "source": [
        "import glob, os\n",
        "#os.chdir(\"..\")\n",
        "print(os.getcwd())\n",
        "\n",
        "os.listdir(os.getcwd())\n",
        "#os.chdir(\"My Drive/Colab Notebooks/\")\n",
        "#print(os.getcwd())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrZmn8AUAveO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        #rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        #zoom_range=0.2,\n",
        "        #horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "\n",
        "for file in glob.glob(\"weird images/NeckerCubeDrawings/healthy/\" + \"*.png\"):\n",
        "    img = load_img(file)  # this is a PIL image\n",
        "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='weird images/NeckerCubeDrawings/healthy', save_format='png'):\n",
        "        i += 1\n",
        "        if i > 15:\n",
        "            break \n",
        "            \n",
        "for file in glob.glob(\"weird images/NeckerCubeDrawings/PD/\" + \"*.png\"):\n",
        "    img = load_img(file)  # this is a PIL image\n",
        "    x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "    x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='weird images/NeckerCubeDrawings/healthy', save_format='png'):\n",
        "        i += 1\n",
        "        if i > 10:\n",
        "            break "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3f8Yj51OxE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "DATADIR = \"weird images/NeckerCubeDrawings\"\n",
        "\n",
        "# All the categories you want your neural network to detect\n",
        "CATEGORIES = [\"healthy\", \"PD\"]\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "IMG_SIZE = 150\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in CATEGORIES :\n",
        "\tpath = os.path.join(DATADIR, category)\n",
        "\tfor img in os.listdir(path):\n",
        "\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "\tfor category in CATEGORIES :\n",
        "\t\tpath = os.path.join(DATADIR, category)\n",
        "\t\tclass_num = CATEGORIES.index(category)\n",
        "\t\tfor img in os.listdir(path):\n",
        "\t\t\ttry :\n",
        "\t\t\t\timg_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\t\t\t\tnew_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\ttraining_data.append([new_array, class_num])\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tpass\n",
        "\n",
        "create_training_data() # contains training_data with images and classes\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "\n",
        "len(X),len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icc-RteKO52a",
        "colab_type": "text"
      },
      "source": [
        "## Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPv7btCO88K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_datatest(x,y):\n",
        "\n",
        "    #Â train and test\n",
        "    X_train = X[:int(0.9*int(len(X)))]\n",
        "    y_train = y[:int(0.9*int(len(X)))]\n",
        "    X_test = X[int(0.9*int(len(X))):]\n",
        "    y_test = y[int(0.9*int(len(y))):]\n",
        "    \n",
        "    # validation\n",
        "    X_train = X_train[:int(0.8*int(len(X_train)))]\n",
        "    y_train = y_train[:int(0.8*int(len(y_train)))]\n",
        "    \n",
        "    X_val = X_train[int(0.8*int(len(X_train))):]\n",
        "    y_val = y_train[int(0.8*int(len(y_train))):]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
        "\n",
        "#len(X_val), len(y_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tns9NEzBO_xB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_validation(X_train,y_train):\n",
        "    X_train = X_train[:int(0.8*int(len(X_train)))]\n",
        "    y_train = y_train[:int(0.8*int(len(y_train)))]\n",
        "    \n",
        "    X_val = X_train[int(0.8*int(len(X_train))):]\n",
        "    y_val = y_train[int(0.8*int(len(y_train))):]\n",
        "    \n",
        "    return X_train, y_train, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbM-Dl4GPBp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = split_datatest(X,y)\n",
        "\n",
        "print(len(X_val), len(y_val),len(X_train), len(y_train), len(X_test), len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53LOpuwPPD1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val):\n",
        "\n",
        "    # reshape training sets to prepare for CNN\n",
        "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_val = np.array(y_val)\n",
        "    \n",
        "    # one hot encoding of pixels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    y_val = to_categorical(y_val)\n",
        "    \n",
        "    train_norm = X_train.astype('float32')\n",
        "    test_norm = X_test.astype('float32')\n",
        "    val_norm = X_val.astype('float32')\n",
        "\n",
        "    # normalize to range 0-1\n",
        "    X_train = train_norm / 255.0\n",
        "    X_test = test_norm / 255.0\n",
        "    X_val = val_norm / 255.0\n",
        "    # return dataset\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP8nJdzePJPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test harness for evaluating models on the cifar10 dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  print(\"Model defined\")\n",
        "  return model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    #pyplot.show()\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "    \n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness(x,y):\n",
        "    \n",
        "    #X_train, y_train, X_test, y_test = create_test(X,y)\n",
        "    \n",
        "    #X_train, y_train, X_val, y_val = create_validation(X_train,y_train)\n",
        "    \n",
        "    X_train, y_train, X_test, y_test, X_val, y_val = split_dataset(X,y)\n",
        "    \n",
        "    X_train, y_train, X_test, y_test, X_val, y_val = prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val)\n",
        "    \n",
        "    print(len(X_val), len(y_val))\n",
        "          \n",
        "    model = define_model()\n",
        "    # fit model\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=24, validation_data=(X_val, y_val), verbose=0)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test Accuracy: %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCFXLt1gPNEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}