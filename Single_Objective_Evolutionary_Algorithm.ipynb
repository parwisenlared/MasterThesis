{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single-Objective Evolutionary Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbNUOgVR6luvudh7Tpy9pM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwisenlared/MasterThesis/blob/master/Single_Objective_Evolutionary_Algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lo7lrZbK7qM",
        "colab_type": "text"
      },
      "source": [
        "## Preparing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w_UVuqgMmgT",
        "colab_type": "text"
      },
      "source": [
        "GA adapted from https://github.com/AlessandroSaviolo/Evolving-CNNs-using-GA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1_-xn3ELB6-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1846cb93-6c03-4fbd-d3ce-7a1532afc079"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfThTAQ6LEjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1d77f500-2bb8-43eb-f2bb-84d03ae3a1b4"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/b&w\" -d \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/My Drive/Colab Notebooks/b&w, /content/drive/My Drive/Colab Notebooks/b&w.zip or /content/drive/My Drive/Colab Notebooks/b&w.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBXoa3KCLG4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c08f8222-b416-43a7-fd39-60b217317b95"
      },
      "source": [
        "import glob, os\n",
        "#os.chdir(\"..\")\n",
        "print(os.getcwd())\n",
        "\n",
        "os.listdir(os.getcwd())\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/\")\n",
        "print(os.getcwd())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeK2-y3kLK8P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ee38e22d-6cdb-4e8a-b92e-7c0ee0734d39"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"images/greyscaleZeroPressure/PentagonSpiralDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"images/greyscaleZeroPressure/PentagonSpiralDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1310, 1310)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOIap83jLMEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset(x,y):\n",
        "\n",
        "    # train and test set (90% training, 10% test)\n",
        "    X_train = X[:int(0.9*int(len(X)))]\n",
        "    y_train = y[:int(0.9*int(len(X)))]\n",
        "    X_test = X[int(0.9*int(len(X))):]\n",
        "    y_test = y[int(0.9*int(len(y))):]\n",
        "    \n",
        "    # validation set (90% training, 10% validation)\n",
        "    X_train = X_train[:int(0.9*int(len(X_train)))]\n",
        "    y_train = y_train[:int(0.9*int(len(y_train)))]\n",
        "    \n",
        "    X_val = X_train[int(0.9*int(len(X_train))):]\n",
        "    y_val = y_train[int(0.9*int(len(y_train))):]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy3lT_VQLc4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val):\n",
        "\n",
        "    # reshape training sets to prepare for CNN\n",
        "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_val = np.array(y_val)\n",
        "    \n",
        "    # one hot encoding of pixels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    y_val = to_categorical(y_val)\n",
        "    \n",
        "    train_norm = X_train.astype('float32')\n",
        "    test_norm = X_test.astype('float32')\n",
        "    val_norm = X_val.astype('float32')\n",
        "\n",
        "    # normalize to range 0-1\n",
        "    X_train = train_norm / 255.0\n",
        "    X_test = test_norm / 255.0\n",
        "    X_val = val_norm / 255.0\n",
        "    # return dataset\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2tM2Z9fIc5f",
        "colab_type": "text"
      },
      "source": [
        "## Evolving CNN with GA algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968Nbji5jljz",
        "colab_type": "text"
      },
      "source": [
        "Code adapted from: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YreWA-g1B89h",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nedb823-IpIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilities\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def load_dataset(X, y, batch_size, num_classes, epochs):  \t\t\t\t\t# retrieve CIFAR10 dataset and process data\n",
        "\n",
        "    x_train, y_train, x_test, y_test, x_val, y_val = split_dataset(X,y)\n",
        "    \n",
        "    x_train, y_train, x_test, y_test, x_val, y_val = prepare_dataset(x_train, y_train, x_test, y_test, x_val, y_val)\n",
        "\n",
        "    dataset = {\n",
        "        'batch_size': batch_size,\n",
        "        'num_classes': num_classes,\n",
        "        'epochs': epochs,\n",
        "        'x_train': x_train,\n",
        "        'x_test': x_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test,\n",
        "        'x_val': x_val,\n",
        "        'y_val': y_val\n",
        "    }\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def save_network(network):\n",
        "    object_file = open(network.name + '.obj', 'wb')\n",
        "    pickle.dump(network, object_file)\n",
        "\n",
        "\n",
        "def load_network(name):\n",
        "    object_file = open(name + '.obj', 'rb')\n",
        "    return pickle.load(object_file)\n",
        "\n",
        "\n",
        "def order_indexes(self):\n",
        "    i = 0\n",
        "    for block in self.block_list:\n",
        "        block.index = i\n",
        "        i += 1\n",
        "\n",
        "\n",
        "def plot_training(history):                                           # plot diagnostic learning curves\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# loss curves\n",
        "    plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.title('Loss Curves', fontsize=16)\n",
        "\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/plots/' + filename + '_loss_plot.png')\n",
        "\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# accuracy curves\n",
        "    plt.plot(history.history['acc'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_acc'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Accuracy', fontsize=16)\n",
        "    plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/' + filename + '_acc_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_statistics(stats):\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
        "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
        "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
        "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
        "    plt.xlabel('Generations', fontsize=16)\n",
        "    plt.ylabel('FitnessValue', fontsize=16)\n",
        "    plt.title('Fitness Curve', fontsize=16)\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/plots/' + filename + '_fitness_plot.png')\n",
        "\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
        "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
        "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
        "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
        "    plt.xlabel('Generations', fontsize=16)\n",
        "    plt.ylabel('ParamsNum', fontsize=16)\n",
        "    plt.title('Parameters Curve', fontsize=16)\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/' + filename + '_params_plot.png')\n",
        "    plt.close()\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvvh0mTlIMCk",
        "colab_type": "text"
      },
      "source": [
        "## Topologies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcjGBFNFIxZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Topologies\n",
        "\n",
        "import keras.layers\n",
        "from random import randint\n",
        "\n",
        "\n",
        "class Block:\n",
        "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
        "\n",
        "\tdef __init__(self, type, index, layerList1, layerList2):\n",
        "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
        "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
        "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
        "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
        "\n",
        "\tdef get_layers(self):\n",
        "\t\treturn self.layerList1 + self.layerList2\n",
        "\n",
        "\tdef get_size(self):\n",
        "\t\treturn len(self.get_layers())\n",
        "'''\n",
        "class Initial:\n",
        "\tdef _init_(self, input_shape):\n",
        "\t\tself.name = \"Define input\"\n",
        "\t\tself.input_shape = input_shape\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.Input(input_shape = self.input_shape))\n",
        "'''\n",
        "class InitConvolutional:\n",
        "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size')\n",
        "\n",
        "\tdef __init__(self, filters, padding, filter_size, input_shape):\n",
        "\t\tself.name = 'Initial Convolutionl Layer'\n",
        "\t\tself.filters = filters\n",
        "\t\tself.padding = padding\n",
        "\t\tself.filter_size = filter_size\n",
        "\t\tself.input_shape = input_shape\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
        "\t\t\t\t\t\t\t\t\t   kernel_size=self.filter_size,\n",
        "\t\t\t\t\t\t\t\t\t   padding=self.padding,\n",
        "\t\t\t\t\t\t\t\t\t   activation='relu',\n",
        "\t\t\t\t\t\t\t\t\t   kernel_initializer='he_uniform',\n",
        "\t\t\t\t\t\t\t\t\t\t input_shape=self.input_shape))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tmutation = randint(0, 2)\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tif mutation == 0 and self.filters >= 64:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 1 and self.filters >= 256:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 2 and self.filters <= 128:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 3 and self.filters <= 256:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\n",
        "\n",
        "class Convolutional:\n",
        "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size')\n",
        "\n",
        "\tdef __init__(self, filters, padding, filter_size):\n",
        "\t\tself.name = 'Conv2D'\n",
        "\t\tself.filters = filters\n",
        "\t\tself.padding = padding\n",
        "\t\tself.filter_size = filter_size\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
        "\t\t\t\t\t\t\t\t\t   kernel_size=self.filter_size,\n",
        "\t\t\t\t\t\t\t\t\t   padding=self.padding,\n",
        "\t\t\t\t\t\t\t\t\t   activation='relu',\n",
        "\t\t\t\t\t\t\t\t\t   kernel_initializer='he_uniform'))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tmutation = randint(0, 2)\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tif mutation == 0 and self.filters >= 64:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 1 and self.filters >= 256:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 2 and self.filters <= 128:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 3 and self.filters <= 256:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\t\n",
        "\n",
        "\n",
        "\n",
        "class Pooling:\n",
        "\t__slots__ = ('name', 'pool_size')\n",
        "\n",
        "\tdef __init__(self, pool_size):\n",
        "\t\tself.name = 'MaxPooling2D'\n",
        "\t\tself.pool_size = pool_size\n",
        "\t\t#self.padding = padding\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tif self.name == 'MaxPooling2D':\n",
        "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size))\n",
        "\t\telif self.name == 'AveragePooling2D':\n",
        "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size))\n",
        "\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"No mutation for Pooling layer\")\n",
        "\t\n",
        "\n",
        "\n",
        "class FullyConnected:\n",
        "\t__slots__ = ('name', 'units', 'num_classes')\n",
        "\n",
        "\tdef __init__(self, units, num_classes):\n",
        "\t\tself.name = \"FullyConnected\"\n",
        "\t\tself.units = units\n",
        "\t\tself.num_classes = num_classes\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Flatten())\n",
        "\t\tmodel.add(keras.layers.Dense(units=self.units, activation='relu', kernel_initializer='he_uniform'))\n",
        "\t\tmodel.add(keras.layers.Dropout(0.5))\n",
        "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tmutation = randint(0, 2)\n",
        "\t\tif mutation == 0:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units *= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\t\telif mutation == 1:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units *= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\t\telif mutation == 2:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units /= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\n",
        "\n",
        "'''\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(self.num_classes, activation='softmax'))\n",
        "'''\n",
        "\n",
        "\n",
        "class Dropout:\n",
        "\t__slots__ = ('name', 'rate')\n",
        "\n",
        "\tdef __init__(self, rate):\n",
        "\t\tself.name = \"Dropout\"\n",
        "\t\tself.rate = rate\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tmutation = randint(0, 3)\n",
        "\t\tif mutation == 0 and self.rate <= 0.85:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate + 0.10\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 1 and self.rate <= 0.90:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate + 0.05\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 2 and self.rate >= 0.15:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate - 0.10\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 3 and self.rate >= 0.10:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate - 0.05\n",
        "\t\t\tprint(\"to \", self.rate)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H48e5XKFII0J",
        "colab_type": "text"
      },
      "source": [
        "## Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j58mTXscIv58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from keras.models import Sequential\n",
        "from random import randint, choice\n",
        "from copy import deepcopy\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "class Network:\n",
        "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
        "\n",
        "    def __init__(self, it):\n",
        "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
        "        self.block_list = []\n",
        "        self.fitness = None\n",
        "        self.model = None\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()                                # create model\n",
        "        for block in self.block_list:\n",
        "            for layer in block.get_layers():                # build model\n",
        "                try:\n",
        "                    layer.build_layer(model)\n",
        "                except:\n",
        "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\", layer.name, block.index)\n",
        "                    return -1\n",
        "        return model\n",
        "\n",
        "    def train_and_evaluate(self, model, dataset):\n",
        "        print(\"Training\", self.name)\n",
        "        opt = SGD(lr=0.001, momentum=0.9)\n",
        "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(dataset['x_train'],\n",
        "                            dataset['y_train'],\n",
        "                            batch_size=dataset['batch_size'],\n",
        "                            epochs=dataset['epochs'],\n",
        "                            validation_data=(dataset['x_val'], dataset['y_val']))\n",
        "\n",
        "        self.model = model                                    # model\n",
        "        _, acc = model.evaluate(dataset['x_test'], dataset['y_test'], verbose=1)                                 \n",
        "        self.fitness = acc         \n",
        "                                   # fitness\n",
        "        print(\"SUMMARY OF\", self.name)\n",
        "        print(model.summary())\n",
        "        print(\"FITNESS: \", self.fitness)\n",
        "\n",
        "        model.save(self.name + '.h5')                       # save model\n",
        "        save_network(self)                                  # save topology, model and fitness\n",
        "\n",
        "    def asexual_reproduction(self, it, dataset):\n",
        "\n",
        "        # if the individual already exists, just load it\n",
        "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
        "            print(\"\\n-------------------------------------\")\n",
        "            print(\"Loading individual net_\" + str(it))\n",
        "            print(\"--------------------------------------\\n\")\n",
        "            individual = load_network('net_' + str(it))\n",
        "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
        "            print(\"SUMMARY OF\", individual.name)\n",
        "            print(model.summary())\n",
        "            print(\"FITNESS: \", individual.fitness)\n",
        "            return individual\n",
        "\n",
        "        # otherwise, create the individual by mutating the parent\n",
        "        individual = Network(it)\n",
        "\n",
        "        print(\"\\n-------------------------------------\")\n",
        "        print(\"\\nCreating individual\", individual.name)\n",
        "        print(\"--------------------------------------\\n\")\n",
        "\n",
        "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
        "\n",
        "        print(\"----->Strong Mutation\")\n",
        "        individual.block_mutation(dataset)                          # mutate a block\n",
        "        individual.layer_mutation(dataset)                          # mutate a layer\n",
        "        individual.parameters_mutation()                            # mutate some parameters\n",
        "\n",
        "        model = individual.build_model()\n",
        "\n",
        "        if model == -1:\n",
        "            return self.asexual_reproduction(it, dataset)\n",
        "\n",
        "        individual.train_and_evaluate(model, dataset)\n",
        "\n",
        "        return individual\n",
        "\n",
        "    def block_mutation(self, dataset):\n",
        "        print(\"Block Mutation\")\n",
        "\n",
        "        print([(block.index, block.type) for block in self.block_list])\n",
        "\n",
        "        # block list containing all the blocks with type = 1\n",
        "        bl = [block.index for block in self.block_list if block.type == 1]\n",
        "\n",
        "        if len(bl) == 0:\n",
        "            print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
        "            self.block_list[1].index = 2\n",
        "            layerList1 = [\n",
        "                Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                              filter_size=(3, 3),\n",
        "                              padding='same'),\n",
        "                Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                              filter_size=(3, 3),\n",
        "                              padding='same')\n",
        "            ]\n",
        "            layerList2 = [\n",
        "                Pooling(pool_size=(2, 2))\n",
        "            ]\n",
        "            b = Block(1, 1, layerList1, layerList2)\n",
        "            self.block_list.insert(1, b)\n",
        "            return\n",
        "\n",
        "        block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
        "        block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
        "        mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
        "\n",
        "        # list of layers of the selected block\n",
        "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
        "        length = len(layerList)\n",
        "\n",
        "        if mutation_type:                                       # remove\n",
        "            if length == 1:\n",
        "                del self.block_list[block_idx]\n",
        "            elif block_type_idx:\n",
        "                pos = randint(0, length - 1)\n",
        "                print(\"Removing a Conv2D layer at\", pos)\n",
        "                del layerList[pos]\n",
        "            else:\n",
        "                pos = randint(0, length - 1)\n",
        "                print(\"Removing a Pooling/Dropout layer at\", pos)\n",
        "                del layerList[pos]\n",
        "        else:                                                   # add\n",
        "            if block_type_idx:\n",
        "                print(\"Inserting a Convolutional layer\")\n",
        "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                      filter_size=(3, 3),\n",
        "                                      padding='same')\n",
        "                layerList.insert(randint(0, length - 1), layer)\n",
        "            else:\n",
        "                if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
        "                    print(\"Inserting a Pooling layer\")\n",
        "                    layer = Pooling(pool_size=(2, 2))\n",
        "                    layerList.insert(randint(0, length - 1), layer)\n",
        "                else:\n",
        "                    print(\"Inserting a Dropout layer\")\n",
        "                    rate = choice([0.15, 0.25, 0.35, 0.50])\n",
        "                    layer = Dropout(rate=rate)\n",
        "                    layerList.insert(randint(0, length - 1), layer)\n",
        "\n",
        "    def layer_mutation(self, dataset):\n",
        "        print(\"Layer Mutation\")\n",
        "\n",
        "        # pick a random block among all the blocks with type = 1\n",
        "        bl = [block.index for block in self.block_list if block.type == 1]\n",
        "\n",
        "        if len(bl) == 0:\n",
        "            return\n",
        "\n",
        "        block_idx = randint(1, max(bl))\n",
        "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
        "\n",
        "        # list of layers of the selected block\n",
        "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
        "\n",
        "        if len(layerList) == 0:\n",
        "            if block_type_idx:\n",
        "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                      filter_size=(3, 3),\n",
        "                                      padding='same',\n",
        "                                      input_shape=dataset['x_train'].shape[1:])\n",
        "                self.block_list[block_idx].layerList1.append(layer)\n",
        "                return\n",
        "            else:\n",
        "                layer = Pooling(pool_size=(2, 2))\n",
        "                self.block_list[block_idx].layerList2.append(layer)\n",
        "\n",
        "        idx = randint(0, len(layerList) - 1)\n",
        "        layer = layerList[idx]\n",
        "\n",
        "        if layer.name == 'Conv2D':\n",
        "            print(\"Splitting Conv2D layer at index\", idx)\n",
        "            layer.filters = int(layer.filters * 0.5)\n",
        "            layerList.insert(idx, deepcopy(layer))\n",
        "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
        "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
        "            del layerList[idx]\n",
        "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                       filter_size=(3, 3), padding = 'same')\n",
        "            layerList.insert(idx, conv_layer)\n",
        "\n",
        "    def parameters_mutation(self):\n",
        "        print(\"Parameters Mutation\")\n",
        "        for block in self.block_list:\n",
        "            for layer in block.get_layers():\n",
        "                if randint(0, 1):\n",
        "                    layer.mutate_parameters()\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1P4xc5tEGrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inout\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#from utilities import load_network\n",
        "#from topology import Block, Convolutional, Pooling, Dropout, FullyConnected\n",
        "#from network import Network\n",
        "\n",
        "\n",
        "def compute_parent(dataset):\n",
        "    if os.path.isfile('parent_0.h5'):\n",
        "        daddy = load_network('parent_0')\n",
        "        model = tf.keras.models.load_model('parent_0.h5')\n",
        "        print(\"Loading parent_0\")\n",
        "        print(\"SUMMARY OF\", daddy.name)\n",
        "        print(model.summary())\n",
        "        print(\"FITNESS:\", daddy.fitness)\n",
        "        return daddy\n",
        "\n",
        "    daddy = Network(0)\n",
        "\n",
        "    \n",
        "    layerList1 = [\n",
        "        InitConvolutional(filters=32, filter_size=(3, 3),  padding='same', \n",
        "                          input_shape=dataset['x_train'].shape[1:]),\n",
        "        Convolutional(filters=32, filter_size=(3, 3), padding='same')\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2)), \n",
        "        Dropout(rate=0.2)\n",
        "    ]\n",
        "\n",
        "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
        "    \n",
        "    layerList1 = [\n",
        "        Convolutional(filters=64, filter_size=(3, 3), padding='same'),\n",
        "        Convolutional(filters=64, filter_size=(3, 3), padding='same')\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2)),\n",
        "        Dropout(rate=0.3)\n",
        "    ]\n",
        "\n",
        "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
        "    \n",
        "    layerList1 = [\n",
        "        Convolutional(filters=128, filter_size=(3, 3), padding='same'),\n",
        "        Convolutional(filters=128, filter_size=(3, 3), padding='same')\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2)),\n",
        "        Dropout(rate=0.4)\n",
        "    ]\n",
        "    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n",
        "    \n",
        "    layerList1 = [\n",
        "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
        "    ]\n",
        "    layerList2 = []\n",
        "\n",
        "    daddy.block_list.append(Block(2, 3, layerList1,layerList2 = []))\n",
        "    \n",
        "    '''\n",
        "    layerList1 = [\n",
        "        InitConvolutional(filters=32, filter_size=(3, 3), padding='same',\n",
        "                      input_shape=dataset['x_train'].shape[1:]),\n",
        "        Convolutional(filters=32, filter_size=(3, 3),  padding='valid')\n",
        "        ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2))\n",
        "    ]\n",
        "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
        "\n",
        "    layerList1 = [\n",
        "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
        "    ]\n",
        "\n",
        "    layerList2 = []\n",
        "\n",
        "    daddy.block_list.append(Block(2, 1, layerList1, layerList2))\n",
        "    \n",
        "'''\n",
        "    model = daddy.build_model()\n",
        "    daddy.train_and_evaluate(model, dataset)\n",
        "    return daddy\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32pifebljS6s",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKE4iPhIIRza",
        "colab_type": "text"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "470O-QoBIcMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Main\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from random import randint, sample\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "def initialize_population(population_size, dataset):\n",
        "    print(\"----->Initializing Population\")\n",
        "    daddy = compute_parent(dataset)                                 # load parent from input\n",
        "    population = [daddy]\n",
        "    for it in range(1, population_size):\n",
        "        population.append(daddy.asexual_reproduction(it, dataset))\n",
        "\n",
        "    # sort population on ascending order based on fitness\n",
        "    return sorted(population, key=lambda cnn: -cnn.fitness)\n",
        "\n",
        "\n",
        "def selection(k, population, num_population):\n",
        "    if k == 0:                                              # elitism selection\n",
        "        print(\"----->Elitism selection\")\n",
        "        return population[0], population[1]\n",
        "    elif k == 1:                                            # tournament selection\n",
        "        print(\"----->Tournament selection\")\n",
        "        i = randint(0, num_population - 1)\n",
        "        j = i\n",
        "        while j < num_population - 1:\n",
        "            j += 1\n",
        "            if randint(1, 100) <= 50:\n",
        "                return population[i], population[j]\n",
        "        return population[i], population[0]\n",
        "    else:                                                   # proportionate selection\n",
        "        print(\"----->Proportionate selection\")\n",
        "        cum_sum = 0\n",
        "        for i in range(num_population):\n",
        "            cum_sum += population[i].fitness\n",
        "        perc_range = []\n",
        "        for i in range(num_population):\n",
        "            count = int(100 * population[i].fitness / cum_sum)\n",
        "            for j in range(count):\n",
        "                perc_range.append(i)\n",
        "        i, j = sample(range(1, len(perc_range)), 2)\n",
        "        while i == j:\n",
        "            i, j = sample(range(1, len(perc_range)), 2)\n",
        "        return population[perc_range[i]], population[perc_range[j]]\n",
        "\n",
        "\n",
        "def crossover(parent1, parent2, it):\n",
        "    print(\"----->Crossover\")\n",
        "    child = Network(it)\n",
        "\n",
        "    first, second = None, None\n",
        "    if randint(0, 1):\n",
        "        first = parent1\n",
        "        second = parent2\n",
        "    else:\n",
        "        first = parent2\n",
        "        second = parent1\n",
        "\n",
        "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
        "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
        "\n",
        "    order_indexes(child)                            # order the indexes of the blocks\n",
        "\n",
        "    return child\n",
        "\n",
        "\n",
        "def genetic_algorithm(num_population, num_generation, num_offspring, dataset):\n",
        "    print(\"Genetic Algorithm\")\n",
        "\n",
        "    population = initialize_population(num_population, dataset)\n",
        "\n",
        "    print(\"\\n-------------------------------------\")\n",
        "    print(\"Initial Population:\")\n",
        "    for cnn in population:\n",
        "        print(cnn.name, ': ', cnn.fitness)\n",
        "    print(\"--------------------------------------\\n\")\n",
        "\n",
        "    # for printing statistics about fitness and number of parameters of the best individual\n",
        "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
        "\n",
        "    for gen in range(1, num_generation + 1):\n",
        "\n",
        "        '''\n",
        "            k is the selection parameter:\n",
        "                k = 0 -> elitism selection\n",
        "                k = 1 -> tournament selection\n",
        "                k = 2 -> proportionate selection\n",
        "        '''\n",
        "        k = randint(0, 2)\n",
        "\n",
        "        print(\"\\n------------------------------------\")\n",
        "        print(\"Generation\", gen)\n",
        "        print(\"-------------------------------------\")\n",
        "\n",
        "        for c in range(num_offspring):\n",
        "\n",
        "            print(\"\\nCreating Child\", c)\n",
        "\n",
        "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
        "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
        "\n",
        "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
        "            print(\"Child has been created\")\n",
        "\n",
        "            print(\"----->Soft Mutation\")\n",
        "            child.layer_mutation(dataset)                                               # mutation\n",
        "            child.parameters_mutation()\n",
        "            print(\"Child has been mutated\")\n",
        "\n",
        "            model = child.build_model()                                                 # evaluation\n",
        "\n",
        "            while model == -1:\n",
        "                child = crossover(parent1, parent2, c + num_population)\n",
        "                child.block_mutation(dataset)\n",
        "                child.layer_mutation(dataset)\n",
        "                child.parameters_mutation()\n",
        "                model = child.build_model()\n",
        "\n",
        "            child.train_and_evaluate(model, dataset)\n",
        "\n",
        "            if child.fitness > population[-1].fitness:                                  # evolve population\n",
        "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
        "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
        "                name = population[-1]\n",
        "                population[-1] = deepcopy(child)\n",
        "                population[-1].name = name\n",
        "                population = sorted(population, key=lambda net: -net.fitness)\n",
        "            else:\n",
        "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
        "\n",
        "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Final Population\")\n",
        "    print(\"-------------------------------------\\n\")\n",
        "    for cnn in population:\n",
        "        print(cnn.name, ': ', cnn.fitness)\n",
        "\n",
        "    print(\"\\n-------------------------------------\")\n",
        "    print(\"Stats\")\n",
        "    for i in range(len(stats)):\n",
        "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
        "    print(\"-------------------------------------\\n\")\n",
        "\n",
        "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
        "    plot_statistics(stats)\n",
        "\n",
        "    return population[0]\n",
        "\n",
        "\n",
        "def main():\n",
        "    batch_size = 24                         # the number of training examples in one forward/backward pass\n",
        "    num_classes = 2                         # number of dataset classes\n",
        "    epochs = 3                              # number of forward and backward passes of all the training examples\n",
        "\n",
        "    '''\n",
        "        dataset contains the hyper parameters for loading data and the dataset:\n",
        "            dataset = {\n",
        "                'batch_size': batch_size,\n",
        "                'num_classes': num_classes,\n",
        "                'epochs': epochs,\n",
        "                'x_train': x_train,\n",
        "                'x_test': x_test,\n",
        "                'y_train': y_train,\n",
        "                'y_test': y_test,\n",
        "                'x_val': x_val,\n",
        "                'y_val': y_val\n",
        "            }\n",
        "    '''\n",
        "    dataset = load_dataset(X, y, batch_size, num_classes, epochs)\n",
        "\n",
        "    num_population = 4\n",
        "    num_generation = 2\n",
        "    num_offspring = 2\n",
        "\n",
        "    # plot the best model obtained\n",
        "    optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
        "\n",
        "    # plot the training and validation loss and accuracy\n",
        "    num_epoch = 3\n",
        "    model = optCNN.build_model()\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(dataset['x_train'],\n",
        "                        dataset['y_train'],\n",
        "                        batch_size=dataset['batch_size'],\n",
        "                        epochs=num_epoch,\n",
        "                        validation_data=(dataset['x_val'], dataset['y_val']),\n",
        "                        verbose=2)\n",
        "    \n",
        "\n",
        "    optCNN.model = model                                         # model\n",
        "    _, acc = model.evaluate(dataset['x_test'], dataset['y_test'], verbose=1)  \n",
        "    \n",
        "    optCNN.fitness = acc                                          # fitness\n",
        "    \n",
        "   \n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"The initial CNN has been evolved successfully in the individual\", optCNN.name)\n",
        "    print(\"-------------------------------------\\n\")\n",
        "    daddy = load_network('parent_0')\n",
        "    model = tf.keras.models.load_model('parent_0.h5')\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Summary of initial CNN\")\n",
        "    print(model.summary())\n",
        "    print(\"Fitness of initial CNN:\", daddy.fitness)\n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Summary of evolved individual\")\n",
        "    print(optCNN.model.summary())\n",
        "    print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
        "    print(\"-------------------------------------\\n\")\n",
        "\n",
        "    plot_training(history)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsJKsVA3Mkkf",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILKBa2SOe-fN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0759c005-9f54-4b32-ddcf-97f139325c60"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Genetic Algorithm\n",
            "----->Initializing Population\n",
            "Loading parent_0\n",
            "SUMMARY OF parent_0\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 200, 200, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 200, 200, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 50, 50, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               10240128  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 10,526,818\n",
            "Trainable params: 10,526,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS: 0.9770992398262024\n",
            "\n",
            "-------------------------------------\n",
            "Loading individual net_1\n",
            "--------------------------------------\n",
            "\n",
            "SUMMARY OF net_1\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 200, 200, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 200, 200, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 100, 100, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 100, 100, 32)      9248      \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 50, 50, 128)       147584    \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 50, 50, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               20480256  \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 20,748,770\n",
            "Trainable params: 20,748,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.9618320465087891\n",
            "\n",
            "-------------------------------------\n",
            "Loading individual net_2\n",
            "--------------------------------------\n",
            "\n",
            "SUMMARY OF net_2\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 200, 200, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 200, 200, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 50, 50, 32)        18464     \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 50, 50, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 50, 50, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 80000)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               10240128  \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 10,416,194\n",
            "Trainable params: 10,416,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.9541984796524048\n",
            "\n",
            "-------------------------------------\n",
            "Loading individual net_3\n",
            "--------------------------------------\n",
            "\n",
            "SUMMARY OF net_3\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 200, 200, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 200, 200, 32)      18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 100, 100, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 100, 100, 128)     73856     \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 100, 100, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 100, 100, 128)     147584    \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 100, 100, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 160000)            0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               20480128  \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 20,813,218\n",
            "Trainable params: 20,813,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.9694656729698181\n",
            "\n",
            "-------------------------------------\n",
            "Initial Population:\n",
            "parent_0 :  0.9770992398262024\n",
            "net_3 :  0.9694656729698181\n",
            "net_1 :  0.9618320465087891\n",
            "net_2 :  0.9541984796524048\n",
            "--------------------------------------\n",
            "\n",
            "\n",
            "------------------------------------\n",
            "Generation 1\n",
            "-------------------------------------\n",
            "\n",
            "Creating Child 0\n",
            "----->Elitism selection\n",
            "Selected parent_0 and net_3 for reproduction\n",
            "----->Crossover\n",
            "Child has been created\n",
            "----->Soft Mutation\n",
            "Layer Mutation\n",
            "Parameters Mutation\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  32  to  64\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.15000000000000002  to  0.2\n",
            "Mutating Conv2D layer:\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  128  to  64\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.45  to  0.55\n",
            "Mutating Conv2D layer:\n",
            "No mutation for Pooling layer\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.3  to  0.25\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  128  to  64\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  128  to  64\n",
            "No mutation for Pooling layer\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.4  to  0.30000000000000004\n",
            "Child has been mutated\n",
            "Training net_4\n",
            "Train on 1061 samples, validate on 107 samples\n",
            "Epoch 1/3\n",
            "1061/1061 [==============================] - 643s 606ms/step - loss: 0.6453 - accuracy: 0.6287 - val_loss: 0.6271 - val_accuracy: 0.7290\n",
            "Epoch 2/3\n",
            "1061/1061 [==============================] - 636s 600ms/step - loss: 0.4058 - accuracy: 0.8219 - val_loss: 0.5284 - val_accuracy: 0.7757\n",
            "Epoch 3/3\n",
            "1061/1061 [==============================] - 638s 602ms/step - loss: 0.2770 - accuracy: 0.8841 - val_loss: 0.4085 - val_accuracy: 0.8318\n",
            "131/131 [==============================] - 19s 142ms/step\n",
            "SUMMARY OF net_4\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 200, 200, 64)      640       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 200, 200, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 100, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 100, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 100, 100, 128)     73856     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 100, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 100, 100, 64)      73792     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 100, 100, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 50, 50, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 50, 50, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 25, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 25, 25, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 25, 25, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 1,586,818\n",
            "Trainable params: 1,586,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.8244274854660034\n",
            "----->Evolution: Child net_4 with fitness 0.8244274854660034 is discarded\n",
            "\n",
            "Creating Child 1\n",
            "----->Elitism selection\n",
            "Selected parent_0 and net_3 for reproduction\n",
            "----->Crossover\n",
            "Child has been created\n",
            "----->Soft Mutation\n",
            "Layer Mutation\n",
            "Splitting Conv2D layer at index 1\n",
            "Parameters Mutation\n",
            "Mutating Hey layer:\n",
            "No mutation for Pooling layer\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.2  to  0.15000000000000002\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  64  to  128\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.3  to  0.25\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  128  to  64\n",
            "Mutating Conv2D layer:\n",
            "Mutating Conv2D layer:\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.45  to  0.4\n",
            "Mutating FullyConnected layer:\n",
            "-->changed self.units from  128  to  256\n",
            "Child has been mutated\n",
            "Training net_5\n",
            "Train on 1061 samples, validate on 107 samples\n",
            "Epoch 1/3\n",
            "1061/1061 [==============================] - 298s 281ms/step - loss: 0.5539 - accuracy: 0.6824 - val_loss: 0.3751 - val_accuracy: 0.9065\n",
            "Epoch 2/3\n",
            "1061/1061 [==============================] - 301s 283ms/step - loss: 0.2448 - accuracy: 0.8954 - val_loss: 0.3513 - val_accuracy: 0.8318\n",
            "Epoch 3/3\n",
            "1061/1061 [==============================] - 297s 280ms/step - loss: 0.1915 - accuracy: 0.9274 - val_loss: 0.1260 - val_accuracy: 0.9439\n",
            "131/131 [==============================] - 9s 67ms/step\n",
            "SUMMARY OF net_5\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_11 (Conv2D)           (None, 200, 200, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 200, 200, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 100, 100, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 100, 100, 128)     36992     \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 100, 100, 64)      73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 50, 50, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 50, 50, 32)        18464     \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 50, 50, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 25, 25, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 20000)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               5120256   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 5,305,762\n",
            "Trainable params: 5,305,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.9618320465087891\n",
            "----->Evolution: Child net_5 with fitness 0.9618320465087891 replaces parent net_2 with fitness 0.9541984796524048\n",
            "\n",
            "------------------------------------\n",
            "Generation 2\n",
            "-------------------------------------\n",
            "\n",
            "Creating Child 0\n",
            "----->Proportionate selection\n",
            "Selected net_1 and net_1 for reproduction\n",
            "----->Crossover\n",
            "Child has been created\n",
            "----->Soft Mutation\n",
            "Layer Mutation\n",
            "Parameters Mutation\n",
            "Mutating Conv2D layer:\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.2  to  0.15000000000000002\n",
            "Mutating Conv2D layer:\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  32  to  64\n",
            "No mutation for Pooling layer\n",
            "Mutating Dropout layer:\n",
            "-->changed self.rate from  0.3  to  0.25\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  128  to  256\n",
            "Mutating Conv2D layer:\n",
            "Child has been mutated\n",
            "Training net_4\n",
            "Train on 1061 samples, validate on 107 samples\n",
            "Epoch 1/3\n",
            "  48/1061 [>.............................] - ETA: 5:43 - loss: 0.7546 - accuracy: 0.4375"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}