{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de ImageGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyoIzs6WjblVia2g2PnPDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwisenlared/MasterThesis/blob/master/Copia_de_ImageGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ozNrHqvp_dFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d14a20b5-d6f7-4fae-9fb0-8c63dc5816b8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FuiQx2avBBDk",
        "colab": {}
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/images\" -d \"/content/drive/My Drive/Colab Notebooks/images\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zMW4PsbMBaeB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80c7fe91-cbfd-4216-c7b2-35b8b1bb93fa"
      },
      "source": [
        "import glob, os\n",
        "#os.chdir(\"..\")\n",
        "print(os.getcwd())\n",
        "\n",
        "#os.listdir(os.getcwd())\n",
        "#os.chdir(\"drive/My Drive/Colab Notebooks/\")\n",
        "#print(os.getcwd())"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-SGlo93oFga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4c1980e-63be-4865-9877-f5e185a195ff"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "DATADIR = \"dataset/images/b&wNoZeroPressure/NeckerCubeDrawings\"\n",
        "\n",
        "# All the categories you want your neural network to detect\n",
        "CATEGORIES = [\"healthy\", \"PD\"]\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"dataset/images/b&wNoZeroPressure/NeckerCubeDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"dataset/images/b&wNoZeroPressure/NeckerCubeDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(106, 106)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "icc-RteKO52a"
      },
      "source": [
        "## Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XJPv7btCO88K",
        "colab": {}
      },
      "source": [
        "def split_dataset(x,y):\n",
        "\n",
        "    # train and test set (90% training, 10% test)\n",
        "    X_train = X[:int(0.9*int(len(X)))]\n",
        "    y_train = y[:int(0.9*int(len(X)))]\n",
        "    X_test = X[int(0.9*int(len(X))):]\n",
        "    y_test = y[int(0.9*int(len(y))):]\n",
        "    \n",
        "    # validation set (90% training, 10% validation)\n",
        "    X_train = X_train[:int(0.9*int(len(X_train)))]\n",
        "    y_train = y_train[:int(0.9*int(len(y_train)))]\n",
        "    \n",
        "    X_val = X_train[int(0.9*int(len(X_train))):]\n",
        "    y_val = y_train[int(0.9*int(len(y_train))):]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
        "\n",
        "#len(X_val), len(y_val)\n",
        "\n"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DbM-Dl4GPBp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6f54173-840b-4289-b6b1-ad55a2257b1f"
      },
      "source": [
        "# To check \n",
        "X_train, y_train, X_test, y_test, X_val, y_val = split_dataset(X,y)\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val)\n",
        "\n",
        "print(len(X_val), len(y_val),len(X_train), len(y_train), len(X_test), len(y_test))\n"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 9 85 85 11 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "53LOpuwPPD1e",
        "colab": {}
      },
      "source": [
        "def prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val):\n",
        "\n",
        "    # reshape training sets to prepare for CNN\n",
        "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_val = np.array(y_val)\n",
        "    \n",
        "    # one hot encoding of pixels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    y_val = to_categorical(y_val)\n",
        "    \n",
        "    train_norm = X_train.astype('float32')\n",
        "    test_norm = X_test.astype('float32')\n",
        "    val_norm = X_val.astype('float32')\n",
        "\n",
        "    # normalize to range 0-1\n",
        "    X_train = train_norm / 255.0\n",
        "    X_test = test_norm / 255.0\n",
        "    X_val = val_norm / 255.0\n",
        "    # return dataset\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zANHvFqRYl12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in X_test:\n",
        "  #print(\"value\" , i.shape)"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kP8nJdzePJPF",
        "colab": {}
      },
      "source": [
        "# test harness for evaluating models on the cifar10 dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  print(\"Model defined\")\n",
        "  return model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    #pyplot.show()\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('/content/drive/My Drive/Colab Notebooks/plots/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "    \n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness(x,y):\n",
        "    \n",
        "    X_train, y_train, X_test, y_test, X_val, y_val = split_dataset(X,y)\n",
        "    \n",
        "    X_train, y_train, X_test, Y_test, X_val, y_val = prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val)\n",
        "    \n",
        "    print(len(X_val), len(y_val))\n",
        "          \n",
        "    model = define_model()\n",
        "    # fit model\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=24, validation_data=(X_val, y_val), verbose=0)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    print('Test Accuracy: %.3f' % (acc * 100.0))\n",
        "\n",
        "    # Kappa statistic\n",
        "\n",
        "    yhat_classes = model.predict_classes(X_test, verbose=0)\n",
        "\n",
        "    y_values = y_test\n",
        "\n",
        "    kappa = cohen_kappa_score(y_values, yhat_classes)\n",
        "\n",
        "\n",
        "    print(\"Kappa value is: \", kappa)\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QCFXLt1gPNEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c64a72bc-0f96-4634-e5aa-6a68ee61300d"
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 9\n",
            "Model defined\n",
            "11/11 [==============================] - 1s 63ms/step\n",
            "Test Accuracy: 54.545\n",
            "Kappa value is:  -0.037735849056603765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8R17YMon-gq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}