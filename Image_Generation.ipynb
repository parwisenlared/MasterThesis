{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Copia de ImageGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOTTCCv0TFkBFLwzNAp1sup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwisenlared/MasterThesis/blob/master/Image_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ozNrHqvp_dFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c5841264-4bdf-4ec7-9447-fe7462d374c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FuiQx2avBBDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ffacf32d-304f-4248-b76d-c22530c2cdac"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/Colab Notebooks/b&w\" -d \"/content/drive/My Drive/Colab Notebooks\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/My Drive/Colab Notebooks/b&w, /content/drive/My Drive/Colab Notebooks/b&w.zip or /content/drive/My Drive/Colab Notebooks/b&w.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kqwHkQOMiWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zMW4PsbMBaeB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3733b0ea-1509-4706-87bf-1cf214993c62"
      },
      "source": [
        "import glob, os\n",
        "#os.chdir(\"..\")\n",
        "print(os.getcwd())\n",
        "\n",
        "#os.listdir(os.getcwd())\n",
        "#os.chdir(\"drive/My Drive/Colab Notebooks/\")\n",
        "#print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-SGlo93oFga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0c9d764d-a8af-41b2-a5a0-26955e69aa81"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"b&wZeroPressure/NeckerCubeDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"b&wZeroPressure/NeckerCubeDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1204, 1204)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "icc-RteKO52a"
      },
      "source": [
        "## Define CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XJPv7btCO88K",
        "colab": {}
      },
      "source": [
        "def split_dataset(x,y):\n",
        "\n",
        "    # train and test set (90% training, 10% test)\n",
        "    X_train = X[:int(0.9*int(len(X)))]\n",
        "    y_train = y[:int(0.9*int(len(X)))]\n",
        "    X_test = X[int(0.9*int(len(X))):]\n",
        "    y_test = y[int(0.9*int(len(y))):]\n",
        "    \n",
        "    # validation set (90% training, 10% validation)\n",
        "    X_train = X_train[:int(0.9*int(len(X_train)))]\n",
        "    y_train = y_train[:int(0.9*int(len(y_train)))]\n",
        "    \n",
        "    X_val = X_train[int(0.9*int(len(X_train))):]\n",
        "    y_val = y_train[int(0.9*int(len(y_train))):]\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val\n",
        "\n",
        "#len(X_val), len(y_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "53LOpuwPPD1e",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "def prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val):\n",
        "\n",
        "    # reshape training sets to prepare for CNN\n",
        "    X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_train = np.array(y_train)\n",
        "    \n",
        "    X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_test = np.array(y_test)\n",
        "    \n",
        "    X_val = np.array(X_val).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "    y_val = np.array(y_val)\n",
        "    \n",
        "    # one hot encoding of pixels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    y_val = to_categorical(y_val)\n",
        "    \n",
        "    train_norm = X_train.astype('float32')\n",
        "    test_norm = X_test.astype('float32')\n",
        "    val_norm = X_val.astype('float32')\n",
        "\n",
        "    # normalize to range 0-1\n",
        "    X_train = train_norm / 255.0\n",
        "    X_test = test_norm / 255.0\n",
        "    X_val = val_norm / 255.0\n",
        "    # return dataset\n",
        "    \n",
        "    return X_train, y_train, X_test, y_test, X_val, y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DbM-Dl4GPBp_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d7396b8-438a-4374-f37a-59b6cacb73a2"
      },
      "source": [
        "# To check \n",
        "X_train, y_train, X_test, y_test, X_val, y_val = split_dataset(X,y)\n",
        "\n",
        "X_train, y_train, X_test, y_test, X_val, y_val = prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val)\n",
        "\n",
        "print(len(X_val), len(y_val),len(X_train), len(y_train), len(X_test), len(y_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98 98 974 974 121 121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zANHvFqRYl12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in X_test:\n",
        "  #print(\"value\" , i.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kP8nJdzePJPF",
        "colab": {}
      },
      "source": [
        "# test harness for evaluating models on the cifar10 dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  # compile model\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  print(\"Model defined\")\n",
        "  return model\n",
        " \n",
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    #pyplot.show()\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig('/content/drive/My Drive/Colab Notebooks/plots/' + filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "    \n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness(x,y):\n",
        "    \n",
        "    X_train, y_train, X_test, y_test, X_val, y_val = split_dataset(X,y)\n",
        "    \n",
        "    X_train, y_train, X_test, Y_test, X_val, y_val = prepare_dataset(X_train, y_train, X_test, y_test, X_val, y_val)\n",
        "    \n",
        "    print(len(X_val), len(y_val))\n",
        "          \n",
        "    model = define_model()\n",
        "    # fit model\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=24, validation_data=(X_val, y_val), verbose=2)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(X_test, Y_test, verbose=1)\n",
        "    print('Test Accuracy: %.3f' % (acc * 100.0))\n",
        "\n",
        "    # Kappa statistic\n",
        "\n",
        "    yhat_classes = model.predict_classes(X_test, verbose=1)\n",
        "\n",
        "    y_values = y_test\n",
        "\n",
        "    kappa = cohen_kappa_score(y_values, yhat_classes)\n",
        "\n",
        "\n",
        "    print(\"Kappa value is: \", kappa)\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CL7Sr2KFMWZB",
        "colab_type": "text"
      },
      "source": [
        "## Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QCFXLt1gPNEk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "92d44cb7-37bf-4712-bc68-ead316b2eb7f"
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98 98\n",
            "Model defined\n",
            "Train on 974 samples, validate on 98 samples\n",
            "Epoch 1/10\n",
            " - 243s - loss: 0.8181 - accuracy: 0.5133 - val_loss: 0.6827 - val_accuracy: 0.5306\n",
            "Epoch 2/10\n",
            " - 241s - loss: 0.6814 - accuracy: 0.5739 - val_loss: 0.6630 - val_accuracy: 0.6429\n",
            "Epoch 3/10\n",
            " - 239s - loss: 0.6657 - accuracy: 0.6006 - val_loss: 0.6534 - val_accuracy: 0.6531\n",
            "Epoch 4/10\n",
            " - 238s - loss: 0.6543 - accuracy: 0.6345 - val_loss: 0.6456 - val_accuracy: 0.7245\n",
            "Epoch 5/10\n",
            " - 239s - loss: 0.6498 - accuracy: 0.6304 - val_loss: 0.6318 - val_accuracy: 0.7041\n",
            "Epoch 6/10\n",
            " - 239s - loss: 0.6375 - accuracy: 0.6283 - val_loss: 0.6230 - val_accuracy: 0.7041\n",
            "Epoch 7/10\n",
            " - 240s - loss: 0.6308 - accuracy: 0.6468 - val_loss: 0.5903 - val_accuracy: 0.7653\n",
            "Epoch 8/10\n",
            " - 238s - loss: 0.6206 - accuracy: 0.6468 - val_loss: 0.5862 - val_accuracy: 0.8061\n",
            "Epoch 9/10\n",
            " - 239s - loss: 0.6102 - accuracy: 0.6684 - val_loss: 0.5651 - val_accuracy: 0.8061\n",
            "Epoch 10/10\n",
            " - 244s - loss: 0.5811 - accuracy: 0.6786 - val_loss: 0.5482 - val_accuracy: 0.8061\n",
            "121/121 [==============================] - 7s 59ms/step\n",
            "Test Accuracy: 71.901\n",
            "121/121 [==============================] - 7s 59ms/step\n",
            "Kappa value is:  0.3533480037723985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qUzDV-VdPqC",
        "colab_type": "text"
      },
      "source": [
        "B&W Zero Pressure Spiral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8R17YMon-gq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60b3feb4-ea68-4e3c-ad59-fc85e81f8057"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"b&wZeroPressure/PentagonSpiralDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"b&wZeroPressure/PentagonSpiralDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1319, 1319)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ9A_qSddWOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "28b4896f-1042-4fcf-8e48-549275756298"
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107 107\n",
            "Model defined\n",
            "Train on 1068 samples, validate on 107 samples\n",
            "Epoch 1/10\n",
            " - 264s - loss: 0.9302 - accuracy: 0.5103 - val_loss: 0.6921 - val_accuracy: 0.5421\n",
            "Epoch 2/10\n",
            " - 263s - loss: 0.6906 - accuracy: 0.5346 - val_loss: 0.6910 - val_accuracy: 0.5047\n",
            "Epoch 3/10\n",
            " - 268s - loss: 0.6876 - accuracy: 0.5459 - val_loss: 0.6915 - val_accuracy: 0.5047\n",
            "Epoch 4/10\n",
            " - 263s - loss: 0.6862 - accuracy: 0.5459 - val_loss: 0.6888 - val_accuracy: 0.5794\n",
            "Epoch 5/10\n",
            " - 269s - loss: 0.6895 - accuracy: 0.5515 - val_loss: 0.6885 - val_accuracy: 0.5981\n",
            "Epoch 6/10\n",
            " - 263s - loss: 0.6851 - accuracy: 0.5627 - val_loss: 0.6866 - val_accuracy: 0.5327\n",
            "Epoch 7/10\n",
            " - 262s - loss: 0.6762 - accuracy: 0.5749 - val_loss: 0.6840 - val_accuracy: 0.5421\n",
            "Epoch 8/10\n",
            " - 267s - loss: 0.6727 - accuracy: 0.5890 - val_loss: 0.6798 - val_accuracy: 0.5794\n",
            "Epoch 9/10\n",
            " - 262s - loss: 0.6805 - accuracy: 0.5618 - val_loss: 0.6781 - val_accuracy: 0.5888\n",
            "Epoch 10/10\n",
            " - 262s - loss: 0.6773 - accuracy: 0.5777 - val_loss: 0.6754 - val_accuracy: 0.5981\n",
            "132/132 [==============================] - 8s 59ms/step\n",
            "Test Accuracy: 54.545\n",
            "132/132 [==============================] - 8s 59ms/step\n",
            "Kappa value is:  0.032258064516129004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfAzZTQIdmV0",
        "colab_type": "text"
      },
      "source": [
        "Grey-scale Zero pressure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggW7s2bddZds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8292cb5-ce6d-4a1e-8844-63f34af63fc8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"images copia/greyscaleNoZeroPressure/PentagonSpiralDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"images copia/greyscaleNoZeroPressure/PentagonSpiralDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1310, 1310)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csW4p6tgdZu2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "f497dded-d750-4f7e-9f25-3cde1c5de86b"
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107 107\n",
            "Model defined\n",
            "Train on 1061 samples, validate on 107 samples\n",
            "Epoch 1/10\n",
            " - 264s - loss: 0.5631 - accuracy: 0.6899 - val_loss: 0.3737 - val_accuracy: 0.8785\n",
            "Epoch 2/10\n",
            " - 260s - loss: 0.2842 - accuracy: 0.8709 - val_loss: 0.2013 - val_accuracy: 0.9439\n",
            "Epoch 3/10\n",
            " - 264s - loss: 0.1575 - accuracy: 0.9472 - val_loss: 0.1037 - val_accuracy: 0.9720\n",
            "Epoch 4/10\n",
            " - 259s - loss: 0.1042 - accuracy: 0.9642 - val_loss: 0.0796 - val_accuracy: 0.9813\n",
            "Epoch 5/10\n",
            " - 263s - loss: 0.0836 - accuracy: 0.9680 - val_loss: 0.0674 - val_accuracy: 0.9720\n",
            "Epoch 6/10\n",
            " - 259s - loss: 0.0805 - accuracy: 0.9680 - val_loss: 0.0668 - val_accuracy: 0.9813\n",
            "Epoch 7/10\n",
            " - 259s - loss: 0.0721 - accuracy: 0.9736 - val_loss: 0.0591 - val_accuracy: 0.9813\n",
            "Epoch 8/10\n",
            " - 263s - loss: 0.0668 - accuracy: 0.9746 - val_loss: 0.0494 - val_accuracy: 0.9813\n",
            "Epoch 9/10\n",
            " - 259s - loss: 0.0643 - accuracy: 0.9764 - val_loss: 0.0707 - val_accuracy: 0.9813\n",
            "Epoch 10/10\n",
            " - 262s - loss: 0.0437 - accuracy: 0.9859 - val_loss: 0.0396 - val_accuracy: 0.9813\n",
            "131/131 [==============================] - 8s 59ms/step\n",
            "Test Accuracy: 98.473\n",
            "131/131 [==============================] - 8s 59ms/step\n",
            "Kappa value is:  0.9679000245037981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7675zN10hkSK",
        "colab_type": "text"
      },
      "source": [
        "Grey Scale Zero Pressure Cube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-7HGkSVhjYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7ed0d107-7676-4b74-a67c-b09021050e48"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "\n",
        "IMG_SIZE = 200\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "  for file in glob.glob(\"greyscaleZeroPressure/NeckerCubeDrawings/healthy/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 0])\n",
        "  \n",
        "  print(len(training_data))\n",
        "\n",
        "  for file in glob.glob(\"greyscaleZeroPressure/NeckerCubeDrawings/PD/\" + \"*.png\"):\n",
        "      img = load_img(file, color_mode = \"grayscale\")  # this is a PIL image\n",
        "      new_image = img_to_array(img)  # this is a Numpy array with shape (200, 200,1)\n",
        "      training_data.append([new_image, 1]) # class is 1 \n",
        "\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data) #shufles the data so it's not control and patient\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "#y = np.array(y)\n",
        "\n",
        "for features, label in training_data:\n",
        "\tX.append(features)\n",
        "\ty.append(label)\n",
        "\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "609\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1311, 1311)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5YFnd7XhwQ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "1d341654-e13d-45b7-b8c9-8b1361bfac6b"
      },
      "source": [
        "run_test_harness(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107 107\n",
            "Model defined\n",
            "Train on 1061 samples, validate on 107 samples\n",
            "Epoch 1/10\n",
            " - 263s - loss: 0.7681 - accuracy: 0.5391 - val_loss: 0.6640 - val_accuracy: 0.6075\n",
            "Epoch 2/10\n",
            " - 259s - loss: 0.6689 - accuracy: 0.5862 - val_loss: 0.6540 - val_accuracy: 0.6636\n",
            "Epoch 3/10\n",
            " - 264s - loss: 0.6513 - accuracy: 0.6041 - val_loss: 0.6373 - val_accuracy: 0.6636\n",
            "Epoch 4/10\n",
            " - 259s - loss: 0.6543 - accuracy: 0.5928 - val_loss: 0.6247 - val_accuracy: 0.7009\n",
            "Epoch 5/10\n",
            " - 263s - loss: 0.6390 - accuracy: 0.6343 - val_loss: 0.6180 - val_accuracy: 0.7103\n",
            "Epoch 6/10\n",
            " - 260s - loss: 0.6253 - accuracy: 0.6305 - val_loss: 0.5954 - val_accuracy: 0.7196\n",
            "Epoch 7/10\n",
            " - 259s - loss: 0.6066 - accuracy: 0.6569 - val_loss: 0.5734 - val_accuracy: 0.6822\n",
            "Epoch 8/10\n",
            " - 264s - loss: 0.6036 - accuracy: 0.6550 - val_loss: 0.5709 - val_accuracy: 0.7196\n",
            "Epoch 9/10\n",
            " - 258s - loss: 0.5997 - accuracy: 0.6560 - val_loss: 0.5683 - val_accuracy: 0.7477\n",
            "Epoch 10/10\n",
            " - 262s - loss: 0.5844 - accuracy: 0.6767 - val_loss: 0.5394 - val_accuracy: 0.7664\n",
            "132/132 [==============================] - 8s 59ms/step\n",
            "Test Accuracy: 73.485\n",
            "132/132 [==============================] - 8s 59ms/step\n",
            "Kappa value is:  0.4709115895556574\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}