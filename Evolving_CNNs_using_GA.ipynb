{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evolving-CNNs-using-GA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM40cBoEHn+kC0D5ImdfqBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parwisenlared/MasterThesis/blob/master/Evolving_CNNs_using_GA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2tM2Z9fIc5f",
        "colab_type": "text"
      },
      "source": [
        "Evolving CNN with GA algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nedb823-IpIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utilities\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import pickle\n",
        "import sys\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def load_dataset(batch_size, num_classes, epochs):  \t\t\t\t\t# retrieve CIFAR10 dataset and process data\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train.astype('float32')\t\t\t\t\t\t\t\t# convert from integers to floats\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\t\t\t\t\t\t\t\t\t\t\t\t\t\t# normalize to range 0-1\n",
        "    x_test /= 255\n",
        "    y_train = to_categorical(y_train, num_classes)  \t\t\t\t\t# one-hot encoding\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    dataset = {\n",
        "        'batch_size': batch_size,\n",
        "        'num_classes': num_classes,\n",
        "        'epochs': epochs,\n",
        "        'x_train': x_train,\n",
        "        'x_test': x_test,\n",
        "        'y_train': y_train,\n",
        "        'y_test': y_test\n",
        "    }\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def save_network(network):\n",
        "    object_file = open(network.name + '.obj', 'wb')\n",
        "    pickle.dump(network, object_file)\n",
        "\n",
        "\n",
        "def load_network(name):\n",
        "    object_file = open(name + '.obj', 'rb')\n",
        "    return pickle.load(object_file)\n",
        "\n",
        "\n",
        "def order_indexes(self):\n",
        "    i = 0\n",
        "    for block in self.block_list:\n",
        "        block.index = i\n",
        "        i += 1\n",
        "\n",
        "\n",
        "def plot_training(history):                                           # plot diagnostic learning curves\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# loss curves\n",
        "    plt.plot(history.history['loss'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Loss', fontsize=16)\n",
        "    plt.title('Loss Curves', fontsize=16)\n",
        "\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_loss_plot.png')\n",
        "\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# accuracy curves\n",
        "    plt.plot(history.history['acc'], 'r', linewidth=3.0)\n",
        "    plt.plot(history.history['val_acc'], 'b', linewidth=3.0)\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "    plt.xlabel('Epochs ', fontsize=16)\n",
        "    plt.ylabel('Accuracy', fontsize=16)\n",
        "    plt.title('Accuracy Curves', fontsize=16)\n",
        "\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_acc_plot.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_statistics(stats):\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
        "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
        "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
        "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
        "    plt.xlabel('Generations', fontsize=16)\n",
        "    plt.ylabel('FitnessValue', fontsize=16)\n",
        "    plt.title('Fitness Curve', fontsize=16)\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_fitness_plot.png')\n",
        "\n",
        "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
        "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
        "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
        "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
        "    plt.xlabel('Generations', fontsize=16)\n",
        "    plt.ylabel('ParamsNum', fontsize=16)\n",
        "    plt.title('Parameters Curve', fontsize=16)\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    plt.savefig(filename + '_params_plot.png')\n",
        "    plt.close()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcjGBFNFIxZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Topologies\n",
        "\n",
        "import keras.layers\n",
        "from random import randint\n",
        "\n",
        "\n",
        "class Block:\n",
        "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
        "\n",
        "\tdef __init__(self, type, index, layerList1, layerList2):\n",
        "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
        "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
        "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
        "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
        "\n",
        "\tdef get_layers(self):\n",
        "\t\treturn self.layerList1 + self.layerList2\n",
        "\n",
        "\tdef get_size(self):\n",
        "\t\treturn len(self.get_layers())\n",
        "\n",
        "\n",
        "class Convolutional:\n",
        "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n",
        "\n",
        "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
        "\t\tself.name = 'Conv2D'\n",
        "\t\tself.filters = filters\n",
        "\t\tself.padding = padding\n",
        "\t\tself.filter_size = filter_size\n",
        "\t\tself.stride_size = stride_size\n",
        "\t\tself.input_shape = input_shape\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
        "\t\t\t\t\t\t\t\t\t   kernel_size=self.filter_size,\n",
        "\t\t\t\t\t\t\t\t\t   strides=self.stride_size,\n",
        "\t\t\t\t\t\t\t\t\t   padding=self.padding,\n",
        "\t\t\t\t\t\t\t\t\t   activation='relu',\n",
        "\t\t\t\t\t\t\t\t\t   kernel_initializer='he_uniform',\n",
        "\t\t\t\t\t\t\t\t\t   input_shape=self.input_shape))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tmutation = randint(0, 4)\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tif mutation == 0 and self.filters >= 32:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 1 and self.filters >= 32:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters = int(self.filters / 2)\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 2 and self.filters <= 512:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 3 and self.filters <= 512:\n",
        "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
        "\t\t\tself.filters *= 2\n",
        "\t\t\tprint(\"to \", self.filters)\n",
        "\t\telif mutation == 4:\n",
        "\t\t\tif self.padding == 'valid':\n",
        "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
        "\t\t\t\tself.padding = 'same'\n",
        "\t\t\t\tprint(\"to \", self.padding)\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
        "\t\t\t\tself.padding = 'valid'\n",
        "\t\t\t\tprint(\"to \", self.padding)\n",
        "\n",
        "\n",
        "'''\n",
        "elif mutation is 4:\n",
        "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
        "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
        "\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n",
        "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
        "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
        "\tprint(\"to \", self.stride_size)\n",
        "'''\n",
        "\n",
        "\n",
        "class Pooling:\n",
        "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
        "\n",
        "\tdef __init__(self, pool_size, stride_size, padding):\n",
        "\t\tself.name = 'MaxPooling2D'\n",
        "\t\tself.pool_size = pool_size\n",
        "\t\tself.stride_size = stride_size\n",
        "\t\tself.padding = padding\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tif self.name == 'MaxPooling2D':\n",
        "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
        "\t\telif self.name == 'AveragePooling2D':\n",
        "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tmutation = randint(0, 1)\n",
        "\t\tif mutation == 0:\n",
        "\t\t\tif self.padding == 'valid':\n",
        "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
        "\t\t\t\tself.padding = 'same'\n",
        "\t\t\t\tprint(\"to \", self.padding)\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
        "\t\t\t\tself.padding = 'valid'\n",
        "\t\t\t\tprint(\"to \", self.padding)\n",
        "\t\telif mutation == 1:\n",
        "\t\t\tif self.name == 'MaxPooling2D':\n",
        "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
        "\t\t\t\tself.name = 'AveragePooling2D'\n",
        "\t\t\t\tprint(\"to \", self.name)\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
        "\t\t\t\tself.name = 'MaxPooling2D'\n",
        "\t\t\t\tprint(\"to \", self.name)\n",
        "\n",
        "\n",
        "'''\n",
        "if mutation is 0:\n",
        "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
        "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
        "\tprint(\"to \", self.stride_size)\n",
        "'''\n",
        "\n",
        "\n",
        "class FullyConnected:\n",
        "\t__slots__ = ('name', 'units', 'num_classes')\n",
        "\n",
        "\tdef __init__(self, units, num_classes):\n",
        "\t\tself.name = \"FullyConnected\"\n",
        "\t\tself.units = units\n",
        "\t\tself.num_classes = num_classes\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Flatten())\n",
        "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
        "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tmutation = randint(0, 2)\n",
        "\t\tif mutation == 0:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units *= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\t\telif mutation == 1:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units *= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\t\telif mutation == 2:\n",
        "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
        "\t\t\tself.units /= 2\n",
        "\t\t\tprint(\"to \", self.units)\n",
        "\n",
        "\n",
        "'''\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(self.num_classes, activation='softmax'))\n",
        "'''\n",
        "\n",
        "\n",
        "class Dropout:\n",
        "\t__slots__ = ('name', 'rate')\n",
        "\n",
        "\tdef __init__(self, rate):\n",
        "\t\tself.name = \"Dropout\"\n",
        "\t\tself.rate = rate\n",
        "\n",
        "\tdef build_layer(self, model):\n",
        "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
        "\n",
        "\tdef mutate_parameters(self):\n",
        "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
        "\t\tmutation = randint(0, 3)\n",
        "\t\tif mutation == 0 and self.rate <= 0.85:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate + 0.10\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 1 and self.rate <= 0.90:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate + 0.05\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 2 and self.rate >= 0.15:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate - 0.10\n",
        "\t\t\tprint(\"to \", self.rate)\n",
        "\t\telif mutation == 3 and self.rate >= 0.10:\n",
        "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
        "\t\t\tself.rate = self.rate - 0.05\n",
        "\t\t\tprint(\"to \", self.rate)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j58mTXscIv58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "from keras.models import Sequential\n",
        "from random import randint, choice\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "class Network:\n",
        "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
        "\n",
        "    def __init__(self, it):\n",
        "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
        "        self.block_list = []\n",
        "        self.fitness = None\n",
        "        self.model = None\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()                                # create model\n",
        "        for block in self.block_list:\n",
        "            for layer in block.get_layers():                # build model\n",
        "                try:\n",
        "                    layer.build_layer(model)\n",
        "                except:\n",
        "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
        "                    return -1\n",
        "        return model\n",
        "\n",
        "    def train_and_evaluate(self, model, dataset):\n",
        "        print(\"Training\", self.name)\n",
        "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(dataset['x_train'],\n",
        "                            dataset['y_train'],\n",
        "                            batch_size=dataset['batch_size'],\n",
        "                            epochs=dataset['epochs'],\n",
        "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
        "                            shuffle=True)\n",
        "\n",
        "        self.model = model                                    # model\n",
        "        self.fitness = history.history['val_loss'][-1]        # fitness\n",
        "\n",
        "        print(\"SUMMARY OF\", self.name)\n",
        "        print(model.summary())\n",
        "        print(\"FITNESS: \", self.fitness)\n",
        "\n",
        "        model.save(self.name + '.h5')                       # save model\n",
        "        save_network(self)                                  # save topology, model and fitness\n",
        "\n",
        "    def asexual_reproduction(self, it, dataset):\n",
        "\n",
        "        # if the individual already exists, just load it\n",
        "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
        "            print(\"\\n-------------------------------------\")\n",
        "            print(\"Loading individual net_\" + str(it))\n",
        "            print(\"--------------------------------------\\n\")\n",
        "            individual = load_network('net_' + str(it))\n",
        "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
        "            print(\"SUMMARY OF\", individual.name)\n",
        "            print(model.summary())\n",
        "            print(\"FITNESS: \", individual.fitness)\n",
        "            return individual\n",
        "\n",
        "        # otherwise, create the individual by mutating the parent\n",
        "        individual = Network(it)\n",
        "\n",
        "        print(\"\\n-------------------------------------\")\n",
        "        print(\"\\nCreating individual\", individual.name)\n",
        "        print(\"--------------------------------------\\n\")\n",
        "\n",
        "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
        "\n",
        "        print(\"----->Strong Mutation\")\n",
        "        individual.block_mutation(dataset)                          # mutate a block\n",
        "        individual.layer_mutation(dataset)                          # mutate a layer\n",
        "        individual.parameters_mutation()                            # mutate some parameters\n",
        "\n",
        "        model = individual.build_model()\n",
        "\n",
        "        if model == -1:\n",
        "            return self.asexual_reproduction(it, dataset)\n",
        "\n",
        "        individual.train_and_evaluate(model, dataset)\n",
        "\n",
        "        return individual\n",
        "\n",
        "    def block_mutation(self, dataset):\n",
        "        print(\"Block Mutation\")\n",
        "\n",
        "        print([(block.index, block.type) for block in self.block_list])\n",
        "\n",
        "        # block list containing all the blocks with type = 1\n",
        "        bl = [block.index for block in self.block_list if block.type == 1]\n",
        "\n",
        "        if len(bl) == 0:\n",
        "            print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
        "            self.block_list[1].index = 2\n",
        "            layerList1 = [\n",
        "                Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                              filter_size=(3, 3),\n",
        "                              stride_size=(1, 1),\n",
        "                              padding='same',\n",
        "                              input_shape=dataset['x_train'].shape[1:]),\n",
        "                Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                              filter_size=(3, 3),\n",
        "                              stride_size=(1, 1),\n",
        "                              padding='same',\n",
        "                              input_shape=dataset['x_train'].shape[1:])\n",
        "            ]\n",
        "            layerList2 = [\n",
        "                Pooling(pool_size=(2, 2),\n",
        "                        stride_size=(2, 2),\n",
        "                        padding='same')\n",
        "            ]\n",
        "            b = Block(1, 1, layerList1, layerList2)\n",
        "            self.block_list.insert(1, b)\n",
        "            return\n",
        "\n",
        "        block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
        "        block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
        "        mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
        "\n",
        "        # list of layers of the selected block\n",
        "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
        "        length = len(layerList)\n",
        "\n",
        "        if mutation_type:                                       # remove\n",
        "            if length == 1:\n",
        "                del self.block_list[block_idx]\n",
        "            elif block_type_idx:\n",
        "                pos = randint(0, length - 1)\n",
        "                print(\"Removing a Conv2D layer at\", pos)\n",
        "                del layerList[pos]\n",
        "            else:\n",
        "                pos = randint(0, length - 1)\n",
        "                print(\"Removing a Pooling/Dropout layer at\", pos)\n",
        "                del layerList[pos]\n",
        "        else:                                                   # add\n",
        "            if block_type_idx:\n",
        "                print(\"Inserting a Convolutional layer\")\n",
        "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                      filter_size=(3, 3),\n",
        "                                      stride_size=(1, 1),\n",
        "                                      padding='same',\n",
        "                                      input_shape=dataset['x_train'].shape[1:])\n",
        "                layerList.insert(randint(0, length - 1), layer)\n",
        "            else:\n",
        "                if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
        "                    print(\"Inserting a Pooling layer\")\n",
        "                    layer = Pooling(pool_size=(2, 2),\n",
        "                                    stride_size=(2, 2),\n",
        "                                    padding='same')\n",
        "                    layerList.insert(randint(0, length - 1), layer)\n",
        "                else:\n",
        "                    print(\"Inserting a Dropout layer\")\n",
        "                    rate = choice([0.15, 0.25, 0.35, 0.50])\n",
        "                    layer = Dropout(rate=rate)\n",
        "                    layerList.insert(randint(0, length - 1), layer)\n",
        "\n",
        "    def layer_mutation(self, dataset):\n",
        "        print(\"Layer Mutation\")\n",
        "\n",
        "        # pick a random block among all the blocks with type = 1\n",
        "        bl = [block.index for block in self.block_list if block.type == 1]\n",
        "\n",
        "        if len(bl) == 0:\n",
        "            return\n",
        "\n",
        "        block_idx = randint(1, max(bl))\n",
        "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
        "\n",
        "        # list of layers of the selected block\n",
        "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
        "\n",
        "        if len(layerList) == 0:\n",
        "            if block_type_idx:\n",
        "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                      filter_size=(3, 3),\n",
        "                                      stride_size=(1, 1),\n",
        "                                      padding='same',\n",
        "                                      input_shape=dataset['x_train'].shape[1:])\n",
        "                self.block_list[block_idx].layerList1.append(layer)\n",
        "                return\n",
        "            else:\n",
        "                layer = Pooling(pool_size=(2, 2),\n",
        "                                stride_size=(2, 2),\n",
        "                                padding='same')\n",
        "                self.block_list[block_idx].layerList2.append(layer)\n",
        "\n",
        "        idx = randint(0, len(layerList) - 1)\n",
        "        layer = layerList[idx]\n",
        "\n",
        "        if layer.name == 'Conv2D':\n",
        "            print(\"Splitting Conv2D layer at index\", idx)\n",
        "            layer.filters = int(layer.filters * 0.5)\n",
        "            layerList.insert(idx, deepcopy(layer))\n",
        "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
        "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
        "            del layerList[idx]\n",
        "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
        "                                       filter_size=(3, 3),\n",
        "                                       stride_size=(2, 2),\n",
        "                                       padding=layer.padding,\n",
        "                                       input_shape=dataset['x_train'].shape[1:])\n",
        "            layerList.insert(idx, conv_layer)\n",
        "\n",
        "    def parameters_mutation(self):\n",
        "        print(\"Parameters Mutation\")\n",
        "        for block in self.block_list:\n",
        "            for layer in block.get_layers():\n",
        "                if randint(0, 1):\n",
        "                    layer.mutate_parameters()\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1P4xc5tEGrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inout\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "#from utilities import load_network\n",
        "#from topology import Block, Convolutional, Pooling, Dropout, FullyConnected\n",
        "#from network import Network\n",
        "\n",
        "\n",
        "def compute_parent(dataset):\n",
        "    if os.path.isfile('parent_0.h5'):\n",
        "        daddy = load_network('parent_0')\n",
        "        model = tf.keras.models.load_model('parent_0.h5')\n",
        "        print(\"Loading parent_0\")\n",
        "        print(\"SUMMARY OF\", daddy.name)\n",
        "        print(model.summary())\n",
        "        print(\"FITNESS:\", daddy.fitness)\n",
        "        return daddy\n",
        "\n",
        "    daddy = Network(0)\n",
        "\n",
        "    layerList1 = [\n",
        "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
        "                      input_shape=dataset['x_train'].shape[1:]),\n",
        "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
        "                      input_shape=dataset['x_train'].shape[1:])\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
        "    ]\n",
        "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
        "    '''\n",
        "    layerList1 = [\n",
        "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
        "                      input_shape=dataset['x_train'].shape[1:]),\n",
        "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
        "                      input_shape=dataset['x_train'].shape[1:])\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same'),\n",
        "        Dropout(rate=0.25)\n",
        "    ]\n",
        "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
        "    \n",
        "    layerList1 = [\n",
        "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
        "                      input_shape=dataset['x_train'].shape[1:]),\n",
        "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
        "                      input_shape=dataset['x_train'].shape[1:])\n",
        "    ]\n",
        "    layerList2 = [\n",
        "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same'),\n",
        "        Dropout(rate=0.25)\n",
        "    ]\n",
        "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
        "    '''\n",
        "    layerList1 = [\n",
        "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
        "    ]\n",
        "    layerList2 = []\n",
        "    daddy.block_list.append(Block(2, 1, layerList1, layerList2))\n",
        "\n",
        "    model = daddy.build_model()\n",
        "    daddy.train_and_evaluate(model, dataset)\n",
        "    return daddy\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "470O-QoBIcMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f01d8a2b-015e-4173-d88f-82f016c94ab7"
      },
      "source": [
        "# Main\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from random import randint, sample\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "\n",
        "def initialize_population(population_size, dataset):\n",
        "    print(\"----->Initializing Population\")\n",
        "    daddy = compute_parent(dataset)                                 # load parent from input\n",
        "    population = [daddy]\n",
        "    for it in range(1, population_size):\n",
        "        population.append(daddy.asexual_reproduction(it, dataset))\n",
        "\n",
        "    # sort population on ascending order based on fitness\n",
        "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
        "\n",
        "\n",
        "def selection(k, population, num_population):\n",
        "    if k == 0:                                              # elitism selection\n",
        "        print(\"----->Elitism selection\")\n",
        "        return population[0], population[1]\n",
        "    elif k == 1:                                            # tournament selection\n",
        "        print(\"----->Tournament selection\")\n",
        "        i = randint(0, num_population - 1)\n",
        "        j = i\n",
        "        while j < num_population - 1:\n",
        "            j += 1\n",
        "            if randint(1, 100) <= 50:\n",
        "                return population[i], population[j]\n",
        "        return population[i], population[0]\n",
        "    else:                                                   # proportionate selection\n",
        "        print(\"----->Proportionate selection\")\n",
        "        cum_sum = 0\n",
        "        for i in range(num_population):\n",
        "            cum_sum += population[i].fitness\n",
        "        perc_range = []\n",
        "        for i in range(num_population):\n",
        "            count = int(100 * population[i].fitness / cum_sum)\n",
        "            for j in range(count):\n",
        "                perc_range.append(i)\n",
        "        i, j = sample(range(1, len(perc_range)), 2)\n",
        "        while i == j:\n",
        "            i, j = sample(range(1, len(perc_range)), 2)\n",
        "        return population[perc_range[i]], population[perc_range[j]]\n",
        "\n",
        "\n",
        "def crossover(parent1, parent2, it):\n",
        "    print(\"----->Crossover\")\n",
        "    child = Network(it)\n",
        "\n",
        "    first, second = None, None\n",
        "    if randint(0, 1):\n",
        "        first = parent1\n",
        "        second = parent2\n",
        "    else:\n",
        "        first = parent2\n",
        "        second = parent1\n",
        "\n",
        "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
        "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
        "\n",
        "    order_indexes(child)                            # order the indexes of the blocks\n",
        "\n",
        "    return child\n",
        "\n",
        "\n",
        "def genetic_algorithm(num_population, num_generation, num_offspring, dataset):\n",
        "    print(\"Genetic Algorithm\")\n",
        "\n",
        "    population = initialize_population(num_population, dataset)\n",
        "\n",
        "    print(\"\\n-------------------------------------\")\n",
        "    print(\"Initial Population:\")\n",
        "    for cnn in population:\n",
        "        print(cnn.name, ': ', cnn.fitness)\n",
        "    print(\"--------------------------------------\\n\")\n",
        "\n",
        "    # for printing statistics about fitness and number of parameters of the best individual\n",
        "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
        "\n",
        "    for gen in range(1, num_generation + 1):\n",
        "\n",
        "        '''\n",
        "            k is the selection parameter:\n",
        "                k = 0 -> elitism selection\n",
        "                k = 1 -> tournament selection\n",
        "                k = 2 -> proportionate selection\n",
        "        '''\n",
        "        k = randint(0, 2)\n",
        "\n",
        "        print(\"\\n------------------------------------\")\n",
        "        print(\"Generation\", gen)\n",
        "        print(\"-------------------------------------\")\n",
        "\n",
        "        for c in range(num_offspring):\n",
        "\n",
        "            print(\"\\nCreating Child\", c)\n",
        "\n",
        "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
        "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
        "\n",
        "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
        "            print(\"Child has been created\")\n",
        "\n",
        "            print(\"----->Soft Mutation\")\n",
        "            child.layer_mutation(dataset)                                               # mutation\n",
        "            child.parameters_mutation()\n",
        "            print(\"Child has been mutated\")\n",
        "\n",
        "            model = child.build_model()                                                 # evaluation\n",
        "\n",
        "            while model == -1:\n",
        "                child = crossover(parent1, parent2, c + num_population)\n",
        "                child.block_mutation(dataset)\n",
        "                child.layer_mutation(dataset)\n",
        "                child.parameters_mutation()\n",
        "                model = child.build_model()\n",
        "\n",
        "            child.train_and_evaluate(model, dataset)\n",
        "\n",
        "            if child.fitness < population[-1].fitness:                                  # evolve population\n",
        "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
        "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
        "                name = population[-1].name\n",
        "                population[-1] = deepcopy(child)\n",
        "                population[-1].name = name\n",
        "                population = sorted(population, key=lambda net: net.fitness)\n",
        "            else:\n",
        "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
        "\n",
        "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Final Population\")\n",
        "    print(\"-------------------------------------\\n\")\n",
        "    for cnn in population:\n",
        "        print(cnn.name, ': ', cnn.fitness)\n",
        "\n",
        "    print(\"\\n-------------------------------------\")\n",
        "    print(\"Stats\")\n",
        "    for i in range(len(stats)):\n",
        "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
        "    print(\"-------------------------------------\\n\")\n",
        "\n",
        "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
        "    plot_statistics(stats)\n",
        "\n",
        "    return population[0]\n",
        "\n",
        "\n",
        "def main():\n",
        "    batch_size = 32                         # the number of training examples in one forward/backward pass\n",
        "    num_classes = 10                        # number of cifar-10 dataset classes\n",
        "    epochs = 3                              # number of forward and backward passes of all the training examples\n",
        "\n",
        "    '''\n",
        "        dataset contains the hyper parameters for loading data and the dataset:\n",
        "            dataset = {\n",
        "                'batch_size': batch_size,\n",
        "                'num_classes': num_classes,\n",
        "                'epochs': epochs,\n",
        "                'x_train': x_train,\n",
        "                'x_test': x_test,\n",
        "                'y_train': y_train,\n",
        "                'y_test': y_test\n",
        "            }\n",
        "    '''\n",
        "    dataset = load_dataset(batch_size, num_classes, epochs)\n",
        "\n",
        "    num_population = 4\n",
        "    num_generation = 4\n",
        "    num_offspring = 2\n",
        "\n",
        "    # plot the best model obtained\n",
        "    optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
        "\n",
        "    # plot the training and validation loss and accuracy\n",
        "    num_epoch = 3\n",
        "    model = optCNN.build_model()\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(dataset['x_train'],\n",
        "                        dataset['y_train'],\n",
        "                        batch_size=dataset['batch_size'],\n",
        "                        epochs=num_epoch,\n",
        "                        validation_data=(dataset['x_test'], dataset['y_test']),\n",
        "                        shuffle=True)\n",
        "    optCNN.model = model                                        # model\n",
        "    optCNN.fitness = history.history['val_loss'][-1]            # fitness\n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"The initial CNN has been evolved successfully in the individual\", optCNN.name)\n",
        "    print(\"-------------------------------------\\n\")\n",
        "    daddy = load_network('parent_0')\n",
        "    model = tf.keras.models.load_model('parent_0.h5')\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Summary of initial CNN\")\n",
        "    print(model.summary())\n",
        "    print(\"Fitness of initial CNN:\", daddy.fitness)\n",
        "\n",
        "    print(\"\\n\\n-------------------------------------\")\n",
        "    print(\"Summary of evolved individual\")\n",
        "    print(optCNN.model.summary())\n",
        "    print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
        "    print(\"-------------------------------------\\n\")\n",
        "\n",
        "    plot_training(history)\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "Genetic Algorithm\n",
            "----->Initializing Population\n",
            "Training parent_0\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 1.3163 - accuracy: 0.5375 - val_loss: 1.0591 - val_accuracy: 0.6286\n",
            "Epoch 2/3\n",
            "50000/50000 [==============================] - 142s 3ms/step - loss: 0.9091 - accuracy: 0.6836 - val_loss: 0.9832 - val_accuracy: 0.6597\n",
            "Epoch 3/3\n",
            "50000/50000 [==============================] - 144s 3ms/step - loss: 0.7273 - accuracy: 0.7504 - val_loss: 0.9747 - val_accuracy: 0.6791\n",
            "SUMMARY OF parent_0\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 7200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               921728    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 933,162\n",
            "Trainable params: 933,162\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "FITNESS:  0.9746851401329041\n",
            "\n",
            "-------------------------------------\n",
            "\n",
            "Creating individual net_1\n",
            "--------------------------------------\n",
            "\n",
            "----->Strong Mutation\n",
            "Block Mutation\n",
            "[(0, 0), (1, 2)]\n",
            "Creating a new block with two Convolutional layers and a Pooling layer\n",
            "Layer Mutation\n",
            "Changing Pooling layer at index 0 with Conv2D layer\n",
            "Parameters Mutation\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.padding from  same  to  valid\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.filters from  32  to  64\n",
            "Mutating MaxPooling2D layer:\n",
            "-->changed self.padding from  same  to  valid\n",
            "Mutating Conv2D layer:\n",
            "-->changed self.padding from  same  to  valid\n",
            "Training net_1\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "50000/50000 [==============================] - 320s 6ms/step - loss: 1.4611 - accuracy: 0.4700 - val_loss: 1.3375 - val_accuracy: 0.5546\n",
            "Epoch 2/3\n",
            "50000/50000 [==============================] - 322s 6ms/step - loss: 0.9779 - accuracy: 0.6570 - val_loss: 0.9230 - val_accuracy: 0.6778\n",
            "Epoch 3/3\n",
            "15872/50000 [========>.....................] - ETA: 3:28 - loss: 0.8142 - accuracy: 0.7165"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nm-kVxJJd_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}